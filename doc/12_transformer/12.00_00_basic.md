# QA

### transformer vs traditional method

* 目前CNN对于海量的数据表现出了瓶颈；
* 目前来看transformer对于海量的数据上限更好，随着数据的增加，performance也在一直变好；
* 可能的原因是CNN模型一旦训练完成，它的参数就是固定的，但是transformer可以随着图的不同，动态的调整参数，这样它的能力就强了很多；
* transformer不光关注value，还要去关注特征之间的联系，更加gene；



# Self-Attention以及Multi-Head Attention

* [Transformer论文逐段精读【论文精读】](https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.788.videocard.2)





# vision transformer 必读系列



* [Vision Transformer 必读系列之图像分类综述(一): 概述](https://mp.weixin.qq.com/s?__biz=MzI4MDcxNTY2MQ==&mid=2247486170&idx=1&sn=3e00f09e3d7519d0a83fd42178206850&chksm=ebb50238dcc28b2ebbb840353ee788dfcc2ae2841c5611e8a62bc0fc893b70bccf2be35f33d2&scene=21#wechat_redirect)
* [Vision Transformer 必读系列之图像分类综述(二): Attention-based](https://mp.weixin.qq.com/s/N9Tt_gCz35Swvhzv0Pz4Sw)



# 超参数

 transformer对参数很敏感，一些超参数设置可以看考下面论文：

* 《2021-Early Convolutions Help Transformers See Better》
* 《2021-DeiT》
